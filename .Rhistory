# install packages if it is not already
if(!require("data.table"))
{
install.packages("data.table")
}
if(!require("ggplot2"))
{
install.packages("ggplot2")
}
if(!require("caTools"))
{
install.packages("caTools")
}
# attach all functions provided by these packages
library(data.table)
library(ggplot2)
library(caTools)
# source NNetOneSplit function
source('NNetOneSplit.R')
setwd("~/CS499/CS499-Project3")
# source NNetOneSplit function
source('NNetOneSplit.R')
#download spam data set to local directory, if it is not present
if(!file.exists("spam.data"))
{
download.file("https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.data", "spam.data")
}
# Read spam data set and convert to input matrix
spam.dt <- data.table::fread("spam.data")
N.obs <- nrow(spam.dt)
X.raw <- as.matrix(spam.dt[, -ncol(spam.dt), with=FALSE])
y.vec <- spam.dt[[ncol(spam.dt)]]
X.mat <- scale(X.raw)
max.epochs <- 10
step.size <- 0.05
n.hidden.units <- c(ncol(X.mat), 20, 1)
# Create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 80T-20F
# is.train contains rows which are in the train set. All other rows not in is.train are in the test set
is.train <- sample.int(n = nrow(X.mat), size = floor(.8*nrow(X.mat)), replace = F)
# create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 60T-40F
# is.subtrain contains rows which are in the train set. All other rows not in is.subtrain are in test set
is.subtrain <- sample.int(n = nrow(X.mat), size = floor(.6*nrow(X.mat)), replace = F)
# Call NNetOne with x.mat, y.vec, with is.subtrain, and large max.epochs
stuff <- NNetOneSplit(X.mat, y.vec, max.epochs, step.size, n.hidden.units, is.subtrain)
max.epochs <- 100
# Read spam data set and convert to input matrix
spam.dt <- data.table::fread("spam.data")
N.obs <- nrow(spam.dt)
X.raw <- as.matrix(spam.dt[, -ncol(spam.dt), with=FALSE])
y.vec <- spam.dt[[ncol(spam.dt)]]
X.mat <- scale(X.raw)
max.epochs <- 100
step.size <- 0.05
n.hidden.units <- c(ncol(X.mat), 20, 1)
# Create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 80T-20F
# is.train contains rows which are in the train set. All other rows not in is.train are in the test set
is.train <- sample.int(n = nrow(X.mat), size = floor(.8*nrow(X.mat)), replace = F)
# create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 60T-40F
# is.subtrain contains rows which are in the train set. All other rows not in is.subtrain are in test set
is.subtrain <- sample.int(n = nrow(X.mat), size = floor(.6*nrow(X.mat)), replace = F)
# Call NNetOne with x.mat, y.vec, with is.subtrain, and large max.epochs
stuff <- NNetOneSplit(X.mat, y.vec, max.epochs, step.size, n.hidden.units, is.subtrain)
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- do.call(rbind, best.weight.vec)
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- do.call(rbind, best.weight.vec)
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- do.call(rbind, stuff[2])
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
View(weight.dt)
View(weight.dt)
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- do.call(rbind, stuff[2])
weight.dt <- data.frame(weight.dt)
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- do.call(rbind, stuff[2])
weight.dt <- data.frame(weight.dt)
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[2]))
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(1L, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ 1, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
NNetOneSplit <-function(X.mat, y.vec, max.epochs, step.size, n.hidden.units, is.subtrain)
{
n.folds <- 5
set.seed(1)
fold.vec <- sample(rep(1:n.folds, l=length(y.vec)))
# lines 7-11 were copied from Hocking's R script. I believe these are false, and should be using is.subtrain
validation.fold <- 1
is.validation <- fold.vec == validation.fold
is.train <- !is.validation
table(is.train)
# is.subtrain should be defining y.train and X.train
yt.train <- y.vec[is.subtrain]
X.train <- X.mat[is.subtrain]
set.seed(1)
weight.mat.list <- list()
for(layer.i in 1:(length(n.hidden.units)-1)){
mat.nrow <- n.hidden.units[[layer.i+1]]
mat.ncol <- n.hidden.units[[layer.i]]
weight.mat.list[[layer.i]] <- matrix(
rnorm(mat.nrow*mat.ncol), mat.nrow, mat.ncol)
}
##create a for loop over epochs
for(layer.i in 1:(length(n.hidden.units)-1))
{
obs.i <- is.subtrain[[layer.i]]
v <- X.train[obs.i]
w <- yt.train[obs.i]
w.list <- 1/(1+exp(-w*v))
grad.list <- list()
for(layer.i in length(weight.mat.list):1)
{
loss.values <- if(layer.i==length(weight.mat.list))
{
LogLoss(w.list, w)
}
else
{
# grad.w <- t(weight.mat.list[[layer.i+1]]) %*% loss.values
grad.w <- t(weight.mat.list[[layer.i+1]]) * loss.values
w.vec <- w.list[[layer.i]]
grad.w * w.vec * (1-w.vec)
grad.list[[layer.i]] <- loss.values %*% t(grad.w)
}
#grad.list[[layer.i]] <- loss.values %*% t(w.list[[layer.i]])
}
v.mat <- weight.mat.list
for(epoch in 1:max.epochs)
{
# v.mat[[layer.i]] <- v.mat[[layer.i]] - step.size * grad.list[[layer.i]]
current.v.mat <- v.mat[[layer.i]]
for( row in nrow(v.mat[[layer.i]]) )
{
current.v.mat <- v.mat[[layer.i]][row]
for( col in length(current.v.mat) )
{
replace <- current.v.mat[col] - step.size * grad.list[[layer.i]][row]
v.mat[[layer.i]][row][col] <- replace
}
}
}
}
return(list(loss.values, v.mat, w.vec, layer.i))
}
LogLoss <- function(prediction, label)
{
log(1+exp(-label*prediction))
}
# install packages if it is not already
if(!require("data.table"))
{
install.packages("data.table")
}
if(!require("ggplot2"))
{
install.packages("ggplot2")
}
if(!require("caTools"))
{
install.packages("caTools")
}
# attach all functions provided by these packages
library(data.table)
library(ggplot2)
library(caTools)
# source NNetOneSplit function
source('NNetOneSplit.R')
#download spam data set to local directory, if it is not present
if(!file.exists("spam.data"))
{
download.file("https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.data", "spam.data")
}
# Read spam data set and convert to input matrix
spam.dt <- data.table::fread("spam.data")
N.obs <- nrow(spam.dt)
X.raw <- as.matrix(spam.dt[, -ncol(spam.dt), with=FALSE])
y.vec <- spam.dt[[ncol(spam.dt)]]
X.mat <- scale(X.raw)
max.epochs <- 100
step.size <- 0.05
n.hidden.units <- c(ncol(X.mat), 20, 1)
# Create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 80T-20F
# is.train contains rows which are in the train set. All other rows not in is.train are in the test set
is.train <- sample.int(n = nrow(X.mat), size = floor(.8*nrow(X.mat)), replace = F)
# create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 60T-40F
# is.subtrain contains rows which are in the train set. All other rows not in is.subtrain are in test set
is.subtrain <- sample.int(n = nrow(X.mat), size = floor(.6*nrow(X.mat)), replace = F)
# Call NNetOne with x.mat, y.vec, with is.subtrain, and large max.epochs
stuff <- NNetOneSplit(X.mat, y.vec, max.epochs, step.size, n.hidden.units, is.subtrain)
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[2]))
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ stuff[4], labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ stuff[[4]], labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
# source NNetOneSplit function
source('NNetOneSplit.R')
#download spam data set to local directory, if it is not present
if(!file.exists("spam.data"))
{
download.file("https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.data", "spam.data")
}
# Read spam data set and convert to input matrix
spam.dt <- data.table::fread("spam.data")
N.obs <- nrow(spam.dt)
X.raw <- as.matrix(spam.dt[, -ncol(spam.dt), with=FALSE])
y.vec <- spam.dt[[ncol(spam.dt)]]
X.mat <- scale(X.raw)
max.epochs <- 100
step.size <- 0.05
n.hidden.units <- c(ncol(X.mat), 20, 1)
# Create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 80T-20F
# is.train contains rows which are in the train set. All other rows not in is.train are in the test set
is.train <- sample.int(n = nrow(X.mat), size = floor(.8*nrow(X.mat)), replace = F)
# create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 60T-40F
# is.subtrain contains rows which are in the train set. All other rows not in is.subtrain are in test set
is.subtrain <- sample.int(n = nrow(X.mat), size = floor(.6*nrow(X.mat)), replace = F)
# Call NNetOne with x.mat, y.vec, with is.subtrain, and large max.epochs
stuff <- NNetOneSplit(X.mat, y.vec, max.epochs, step.size, n.hidden.units, is.subtrain)
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[2]))
# source NNetOneSplit function
source('NNetOneSplit.R')
#download spam data set to local directory, if it is not present
if(!file.exists("spam.data"))
{
download.file("https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.data", "spam.data")
}
# Read spam data set and convert to input matrix
spam.dt <- data.table::fread("spam.data")
N.obs <- nrow(spam.dt)
X.raw <- as.matrix(spam.dt[, -ncol(spam.dt), with=FALSE])
y.vec <- spam.dt[[ncol(spam.dt)]]
X.mat <- scale(X.raw)
max.epochs <- 100
step.size <- 0.05
n.hidden.units <- c(ncol(X.mat), 20, 1)
# Create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 80T-20F
# is.train contains rows which are in the train set. All other rows not in is.train are in the test set
is.train <- sample.int(n = nrow(X.mat), size = floor(.8*nrow(X.mat)), replace = F)
# create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 60T-40F
# is.subtrain contains rows which are in the train set. All other rows not in is.subtrain are in test set
is.subtrain <- sample.int(n = nrow(X.mat), size = floor(.6*nrow(X.mat)), replace = F)
# Call NNetOne with x.mat, y.vec, with is.subtrain, and large max.epochs
stuff <- NNetOneSplit(X.mat, y.vec, max.epochs, step.size, n.hidden.units, is.subtrain)
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[2]))
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ stuff[[4]], labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ stuff[4], labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ stuff[[4]], labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[2]))
layer.i <- stuff[[4]]
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i], labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
# source NNetOneSplit function
source('NNetOneSplit.R')
#download spam data set to local directory, if it is not present
if(!file.exists("spam.data"))
{
download.file("https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.data", "spam.data")
}
# Read spam data set and convert to input matrix
spam.dt <- data.table::fread("spam.data")
N.obs <- nrow(spam.dt)
X.raw <- as.matrix(spam.dt[, -ncol(spam.dt), with=FALSE])
y.vec <- spam.dt[[ncol(spam.dt)]]
X.mat <- scale(X.raw)
max.epochs <- 100
step.size <- 0.05
n.hidden.units <- c(ncol(X.mat), 20, 1)
# Create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 80T-20F
# is.train contains rows which are in the train set. All other rows not in is.train are in the test set
is.train <- sample.int(n = nrow(X.mat), size = floor(.8*nrow(X.mat)), replace = F)
# create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 60T-40F
# is.subtrain contains rows which are in the train set. All other rows not in is.subtrain are in test set
is.subtrain <- sample.int(n = nrow(X.mat), size = floor(.6*nrow(X.mat)), replace = F)
# Call NNetOne with x.mat, y.vec, with is.subtrain, and large max.epochs
stuff <- NNetOneSplit(X.mat, y.vec, max.epochs, step.size, n.hidden.units, is.subtrain)
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[2]))
layer.i <- stuff[[4]]
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i], labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
# best_epochs = epochs to minimize validation loss
best.epochs <- 10
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[3]))
layer.i <- stuff[[4]]
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
# best_epochs = epochs to minimize validation loss
best.epochs <- 10
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[1]))
layer.i <- stuff[[4]]
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[2]))
layer.i <- stuff[[4]]
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
# source NNetOneSplit function
source('NNetOneSplit.R')
#download spam data set to local directory, if it is not present
if(!file.exists("spam.data"))
{
download.file("https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.data", "spam.data")
}
# Read spam data set and convert to input matrix
spam.dt <- data.table::fread("spam.data")
N.obs <- nrow(spam.dt)
X.raw <- as.matrix(spam.dt[, -ncol(spam.dt), with=FALSE])
y.vec <- spam.dt[[ncol(spam.dt)]]
X.mat <- scale(X.raw)
max.epochs <- 100
step.size <- 0.05
n.hidden.units <- c(ncol(X.mat), 20, 1)
# Create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 80T-20F
# is.train contains rows which are in the train set. All other rows not in is.train are in the test set
is.train <- sample.int(n = nrow(X.mat), size = floor(.8*nrow(X.mat)), replace = F)
# create vector with size = num observations in the whole data set
# elements are TRUE if observation is in train set, FALSE otherwise. Should be 60T-40F
# is.subtrain contains rows which are in the train set. All other rows not in is.subtrain are in test set
is.subtrain <- sample.int(n = nrow(X.mat), size = floor(.6*nrow(X.mat)), replace = F)
# Call NNetOne with x.mat, y.vec, with is.subtrain, and large max.epochs
stuff <- NNetOneSplit(X.mat, y.vec, max.epochs, step.size, n.hidden.units, is.subtrain)
# Plot subtrain/validation loss as fxn of num epochs, draw point to emphasize min validation loss
weight.dt <- data.frame(do.call(rbind, stuff[2]))
layer.i <- stuff[[4]]
ggplot()+
theme_bw()+
theme(panel.spacing=grid::unit(0, "lines"))+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
ggplot()+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)+
scale_fill_gradient2()+
coord_equal()
gplot()+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)
ggplot()+
facet_grid(. ~ layer.i, labeller=label_both)+
geom_tile(aes(
x=input, y=output, fill=weight),
data=weight.dt)
